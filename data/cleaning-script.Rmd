---
title: "Data Cleaning and Aggregation"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Required Packages 

```{r, message=FALSE}
library(tidyverse)
library(RColorBrewer)
```

## Loading in Our Shapefile Data

Before we can synthesize the relevant variables from our two identified data sources into a single matrix, we will need to first read in the nation-state shapefile data local to the `maps` package within `tidyverse`. 

```{r, message=TRUE}
map_data <- map_data("world") 
map_data %>%
  head(5)
```

Because the directory of nation-states used in this package does not adhere to the conventions laid out by the International Organization for Standardization (ISO), we will need to make a series of manual changes to better align our shapefile data with our university-enrollment and dietary-footprint data.

Using the instructions laid out by Thomas Haslam in his 2021 [*RPubs* entry](https://rpubs.com/Thom_JH/798825), we can begin by addressing what he refers to as the "easy cases."

In the mentioned [*RPubs* entry](https://rpubs.com/Thom_JH/798825) entry, Haslam identifies a total of 21 differences between the nation-states listed in the `maps` package and countries listed by [Gapminder](gapminder.org). 

The "easy cases," then, refer to the 13 instances where the names of the `regions` listed in the `maps` package and the countries listed by Gapminder are incongruent.

```{r}
map_data_iso <- map_data %>% 
  rename(country=region) %>%
  mutate(country=case_when(country=="Macedonia"~"North Macedonia",
                           country=="Ivory Coast"~"Cote d'Ivoire",
                           country=="Democratic Republic of the Congo"~"Congo, Dem. Rep.",
                           country=="Republic of Congo"~"Congo, Rep.",
                           country=="UK"~"United Kingdom",
                           country=="USA"~"United States",
                           country=="Laos"~"Lao",
                           country=="Slovakia"~"Slovak Republic",
                           country=="Saint Lucia"~"St. Lucia",
                           country=="Kyrgyzstan"~"Krygyz Republic",
                           country=="Micronesia"~"Micronesia, Fed. Sts.",
                           country=="Swaziland"~"Eswatini",
                           country=="Virgin Islands"~"Virgin Islands (U.S.)",
                        TRUE~country))
```

The second group of instances, which he refers to as the "island nations", refer to the 8 cases where discrete island `region` need to be aggregated to match the related `country` designations provided by [Gapminder](gapminder.org) and the ISO. 

```{r}
island_nations <- c("Antigua","Barbuda","Nevis", 
                 "Saint Kitts","Trinidad",
                 "Tobago","Grenadines","Saint Vincent")
island_nations_match <- map_data_iso %>% 
  filter(country %in% island_nations)
island_nations_match %>% distinct(country)
```

```{r}
ant_bar <- c(137,138 )
kit_nev <- c(930,931)
tri_tog <- c(1425,1426)
vin_gre <- c(1575,1576,1577)
island_nation_names <- c("Antigua and Barbuda","St. Kitts and Nevis","Trinidad and Tobago","St. Vincent and the Grenadines")
island_nations_match <- island_nations_match %>% 
  mutate(country=case_when(group %in% ant_bar~"Antigua and Barbuda",
                           group %in% kit_nev~"St. Kitts and Nevis",
                           group %in% tri_tog~"Trinidad and Tobago",
                           group %in% vin_gre~"St. Vincent and the Grenadines")) %>% 
  tibble()
```

```{r}
island_nations_match %>%
  distinct(country) 
```

```{r}
map_data_iso <- map_data_iso %>%
  filter(!country %in% island_nation_names)
map_data_iso <- map_data_iso %>% 
  bind_rows(island_nations_match) %>%
  arrange(country) %>%
  tibble()
```

Now, we move onto the final 2 cases that we will be addressing. Haslam refers to these as the instances of "subregion promotion". Here, we take Macao and Hong Kong, Special Administrative Regions of China designated as subregions in the `maps` package, and assign them as countries, as is convention for global studies research. 

```{r}
sra_names <- c("Hong Kong","Macao")
hk_mc <- map_data_iso %>% 
  filter(subregion %in% sra_names)
hk_mc <- hk_mc %>%
  mutate(country = case_when(subregion=="Hong Kong"~"Hong Kong, China",
                             subregion=="Macao"~"Macao, China"))
```

```{r}
map_data_iso <- map_data_iso %>%
  filter(!subregion %in% sra_names)
map_data_iso <- map_data_iso %>% 
  bind_rows(hk_mc) %>%
  select(-subregion) %>% 
  tibble()
```

With these each of these steps complete, the regions accounted for within our shapefile data are now as follows: 

```{r}
map_data_iso %>% distinct(country)
```

## Loading in Our Dietary Footprint Data

Before we can spatially join the relevant columns from our dietary footprint data with our updated shapefile data, we will need to first read in the corresponding file from the `parent-datasets` folder in our repository.

```{r}
dietary_footprint_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/dietary_footprint_data.csv")
dietary_footprint_data %>%
  head(6)
```

Because this dataset is not currently formatted in a way that aligns with the demands of our analysis, we will need to make several changes in preparation for our spatial join. 

For each country listed, we need to wrangle the baseline data such that there is a column corresponding to the quantities listed in the `value`, `centile_up`, and `centile_down` for each of the following attributes:`kg_co2e_excl_luc`, `kg_co2e_total`, `l_blue_wf_total`, `l_green_wf`, and `l_blue_green_wf`. In addition, this process needs to be repeated for each of the 8 remaining dietary conditions of interest: `2/3_vegan`, `baseline`, `lacto_ovo_vegetarian`, `low_red_meat`, `meatless_day`, `no_dairy`, `no_red_meat`, and `vegan`.

To adjust for these requirements, we will first select out the relevant variables.

```{r}
dietary_footprint_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/dietary_footprint_data.csv") %>%
  select(country,diet,attribute,value)
dietary_footprint_data %>%
  head(6)
```

With this accomplished, we will continue the wrangling process by pivoting to a wider format. We will achieve this by assigning the different dietary scenarios and attributes designated under the `diet` and `attribute` columns, respectively, as variables rather than observations.

```{r}
dietary_footprint_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/dietary_footprint_data.csv") %>%
  select(country,diet,attribute,value) %>%
  pivot_wider(names_from=c(diet,attribute),
              values_from="value")
dietary_footprint_data %>%
  head(6)
```

Finally, with these new variables generated we will, again, select out the combinations of dietary scenarios and attributes relevant to our analyses. 

```{r}
dietary_footprint_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/dietary_footprint_data.csv") %>%
  select(country,diet,attribute,value) %>%
  pivot_wider(names_from=c(diet,attribute),
              values_from="value") %>%
  select(country,
  "baseline_kg_co2e_excl_luc",
  "baseline_kg_co2e_total",
  "baseline_l_blue_green_wf",
  "baseline_l_blue_wf_total",
  "baseline_l_green_wf",
  "meatless_day_kg_co2e_excl_luc",
  "meatless_day_kg_co2e_total",
  "meatless_day_l_blue_green_wf",
  "meatless_day_l_blue_wf_total",
  "meatless_day_l_green_wf",
  "no_dairy_kg_co2e_excl_luc",
  "no_dairy_kg_co2e_total",
  "no_dairy_l_blue_green_wf",
  "no_dairy_l_blue_wf_total",
  "no_dairy_l_green_wf",
  "low_red_meat_kg_co2e_excl_luc",
  "low_red_meat_kg_co2e_total",
  "low_red_meat_l_blue_green_wf",
  "low_red_meat_l_blue_wf_total",
  "low_red_meat_l_green_wf",
  "no_red_meat_kg_co2e_excl_luc",
  "no_red_meat_kg_co2e_total",
  "no_red_meat_l_blue_green_wf",
  "no_red_meat_l_blue_wf_total",
  "no_red_meat_l_green_wf",
  "pescetarian_kg_co2e_excl_luc",
  "pescetarian_kg_co2e_total",
  "pescetarian_l_blue_green_wf",
  "pescetarian_l_blue_wf_total",
  "pescetarian_l_green_wf",
  "lacto_ovo_vegetarian_kg_co2e_excl_luc",
  "lacto_ovo_vegetarian_kg_co2e_total",
  "lacto_ovo_vegetarian_l_blue_green_wf",
  "lacto_ovo_vegetarian_l_blue_wf_total",
  "lacto_ovo_vegetarian_l_green_wf",
  "2/3_vegan_kg_co2e_excl_luc",
  "2/3_vegan_kg_co2e_total",
  "2/3_vegan_l_blue_green_wf",
  "2/3_vegan_l_blue_wf_total",
  "2/3_vegan_l_green_wf",
  "vegan_kg_co2e_excl_luc",
  "vegan_kg_co2e_total",
  "vegan_l_blue_green_wf",
  "vegan_l_blue_wf_total",
  "vegan_l_green_wf")
dietary_footprint_data %>%
  head(6)
```

Finally, we will need to perform the necessary checks to ensure that country names are consistent across the data sources used for our map and dietary footprint variables.

We will also eventually need to use the `mutate` function to generate averages across scenarios.

## Spatially Joining Our Dietary Footprint Data

map gap

## Loading in Our University Enrollment Data

As we did for our dietary footprint data, we will need to read in and wrangle the university enrollment data found in the `parent-datasets` folder of our repository.

```{r}
university_enrollment_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/university_enrollment_data.csv") %>%
  as_tibble()
university_enrollment_data %>%
  head(6)
```

Before we can spatially join the relevant variables from this data source, we will need to make it so that the data associated with each included country is captured in a single row, and each subsequent column captures the following: (1) the total number of students enrolled in ISCED 6 programs, (2) the total number of students enrolled in ISCED 7 programs, (3) the total number of students enrolled in ISCED 8 programs, (4) the total number of people living within the country, and (5) the reference year being used for each of these variables.

We will begin this process by selecting out the `Country.Code` and `Series.Code` columns, slicing out the 5 bottommost rows, and renaming the `Country.Name`, `Series`, and reference year variables.

```{r}
university_enrollment_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/university_enrollment_data.csv") %>%
  select(-Country.Code,-Series.Code) %>%
  as_tibble(university_enrollment_data) %>%
  slice(1:(n()-5)) %>%
  rename(country=Country.Name,series=Series,yr2000=YR2000,yr2001=YR2001,yr2002=YR2002,yr2003=YR2003,yr2004=YR2004,yr2005=YR2005,yr2006=YR2006,yr2007=YR2007,yr2008=YR2008,yr2009=YR2009,yr2010=YR2010,yr2011=YR2011,yr2012=YR2012,yr2013=YR2013,yr2014=YR2014,yr2015=YR2015,yr2016=YR2016,yr2017=YR2017,yr2018=YR2018,yr2019=YR2019,yr2020=YR2020) 
university_enrollment_data %>%
  tail(6)
```

With this complete, we now need to convert the reference year columns from character strings (`chr`) to double strings (`dbl`), which will coincidently convert the default `--` entries to `NA` values.

```{r}
university_enrollment_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/university_enrollment_data.csv") %>%
  select(-Country.Code,-Series.Code) %>%
  as_tibble(university_enrollment_data) %>%
  slice(1:(n()-5)) %>%
  rename(country=Country.Name,series=Series,yr2000=YR2000,yr2001=YR2001,yr2002=YR2002,yr2003=YR2003,yr2004=YR2004,yr2005=YR2005,yr2006=YR2006,yr2007=YR2007,yr2008=YR2008,yr2009=YR2009,yr2010=YR2010,yr2011=YR2011,yr2012=YR2012,yr2013=YR2013,yr2014=YR2014,yr2015=YR2015,yr2016=YR2016,yr2017=YR2017,yr2018=YR2018,yr2019=YR2019,yr2020=YR2020) %>%
  mutate_at(c("yr2000","yr2001","yr2002","yr2003","yr2004","yr2005","yr2006","yr2007","yr2008","yr2009","yr2010","yr2011","yr2012","yr2013","yr2014","yr2015","yr2016","yr2017","yr2018","yr2019","yr2020"),as.double)
university_enrollment_data %>%
  head(6)
```

We will now turn all of the NA variables in the reference year columns from `NA` values to zero in order to more easily set up our conditional rules for pulling the most recent year with recorded data.

```{r}
university_enrollment_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/university_enrollment_data.csv") %>%
  select(-Country.Code,-Series.Code) %>%
  as_tibble(university_enrollment_data) %>%
  slice(1:(n()-5)) %>%
  rename(country=Country.Name,series=Series,yr2000=YR2000,yr2001=YR2001,yr2002=YR2002,yr2003=YR2003,yr2004=YR2004,yr2005=YR2005,yr2006=YR2006,yr2007=YR2007,yr2008=YR2008,yr2009=YR2009,yr2010=YR2010,yr2011=YR2011,yr2012=YR2012,yr2013=YR2013,yr2014=YR2014,yr2015=YR2015,yr2016=YR2016,yr2017=YR2017,yr2018=YR2018,yr2019=YR2019,yr2020=YR2020) %>%
  mutate_at(c("yr2000","yr2001","yr2002","yr2003","yr2004","yr2005","yr2006","yr2007","yr2008","yr2009","yr2010","yr2011","yr2012","yr2013","yr2014","yr2015","yr2016","yr2017","yr2018","yr2019","yr2020"),as.double) %>%
  replace(is.na(.),0)
university_enrollment_data %>%
  head(6)
```

Now, we will pivot our dataframe so that the different variables of interest currently captured in the `series` column are instead represented as their own variables.

```{r}
university_enrollment_data <- read.csv("/Users/kenjinchang/github/university-dining-impact-model/parent-datasets/university_enrollment_data.csv") %>%
  select(-Country.Code,-Series.Code) %>%
  as_tibble(university_enrollment_data) %>%
  slice(1:(n()-5)) %>%
  rename(country=Country.Name,series=Series,yr2000=YR2000,yr2001=YR2001,yr2002=YR2002,yr2003=YR2003,yr2004=YR2004,yr2005=YR2005,yr2006=YR2006,yr2007=YR2007,yr2008=YR2008,yr2009=YR2009,yr2010=YR2010,yr2011=YR2011,yr2012=YR2012,yr2013=YR2013,yr2014=YR2014,yr2015=YR2015,yr2016=YR2016,yr2017=YR2017,yr2018=YR2018,yr2019=YR2019,yr2020=YR2020) %>%
  mutate_at(c("yr2000","yr2001","yr2002","yr2003","yr2004","yr2005","yr2006","yr2007","yr2008","yr2009","yr2010","yr2011","yr2012","yr2013","yr2014","yr2015","yr2016","yr2017","yr2018","yr2019","yr2020"),as.double) %>%
  replace(is.na(.),0) %>%
  distinct() %>%
  mutate(series=str_replace(series,"isced6","Enrolment in tertiary education, ISCED 6 programmes, both sexes (number) "))
university_enrollment_data %>%
  head(6)
```

  group_by(country) %>%
  mutate(row=row_number()) %>%
  
pivot_wider(names_from="series",
              values_from=c("yr2020","yr2019"))
  
Because we want to use the available data from the most recently provided record, we will need to construct two new columns: one that pulls the numeric quantity of students enrolled from each class of ISCED programs and a second documenting the reference year being used.

```{r}

```
    
## Spatially Joining Our University Enrollment Data

map gap

## Writing the Final Data File


